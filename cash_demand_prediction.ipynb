{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d31b2b3d-9d5e-4e6f-9881-c7bd46adbdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Imports & config\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "CSV_PATH = \"branch_cash_data.csv\"   # <-- change me\n",
    "TEST_DAYS = 90                      # last N days = test window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2e1da44-0e3c-4b32-8da6-5630cdb3866b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20160 entries, 0 to 20159\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   branch_id        20160 non-null  string \n",
      " 1   date             20160 non-null  object \n",
      " 2   atm_withdrawals  19758 non-null  float64\n",
      " 3   otc_withdrawals  19758 non-null  float64\n",
      " 4   is_holiday       20160 non-null  Int8   \n",
      " 5   is_payday        20160 non-null  Int8   \n",
      " 6   cash_deposits    20160 non-null  float64\n",
      " 7   is_branch_open   20060 non-null  Int8   \n",
      "dtypes: Int8(3), float64(3), object(1), string(1)\n",
      "memory usage: 905.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>branch_id</th>\n",
       "      <th>date</th>\n",
       "      <th>atm_withdrawals</th>\n",
       "      <th>otc_withdrawals</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_payday</th>\n",
       "      <th>cash_deposits</th>\n",
       "      <th>is_branch_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B004</td>\n",
       "      <td>5/10/23</td>\n",
       "      <td>18942.85</td>\n",
       "      <td>21388.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13910.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B002</td>\n",
       "      <td>5/16/25</td>\n",
       "      <td>30546.53</td>\n",
       "      <td>28107.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25078.09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B008</td>\n",
       "      <td>11/15/18</td>\n",
       "      <td>19224.35</td>\n",
       "      <td>15983.56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20045.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B002</td>\n",
       "      <td>8/22/23</td>\n",
       "      <td>34942.60</td>\n",
       "      <td>22944.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19811.85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B007</td>\n",
       "      <td>8/7/22</td>\n",
       "      <td>13652.40</td>\n",
       "      <td>9779.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6030.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  branch_id      date  atm_withdrawals  otc_withdrawals  is_holiday  \\\n",
       "0      B004   5/10/23         18942.85         21388.36           0   \n",
       "1      B002   5/16/25         30546.53         28107.67           0   \n",
       "2      B008  11/15/18         19224.35         15983.56           0   \n",
       "3      B002   8/22/23         34942.60         22944.67           0   \n",
       "4      B007    8/7/22         13652.40          9779.20           0   \n",
       "\n",
       "   is_payday  cash_deposits  is_branch_open  \n",
       "0          0       13910.23               1  \n",
       "1          0       25078.09               1  \n",
       "2          1       20045.88               1  \n",
       "3          0       19811.85               1  \n",
       "4          0        6030.40               1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Me being me -- Load + quick check *** You don't need this prod/real run\n",
    "# df = pd.read_csv(CSV_PATH, parse_dates=[\"date\"]) # works but old way\n",
    "df = pd.read_csv(\n",
    "    CSV_PATH,\n",
    "    parse_dates=[\"date\"],\n",
    "    date_format=\"%Y-%m-%d\",          # <-- removes the warning & speeds up parsing. new Micah way\n",
    "    dtype={\n",
    "        \"branch_id\": \"string\",\n",
    "        \"atm_withdrawals\": \"float64\",\n",
    "        \"otc_withdrawals\": \"float64\",\n",
    "        \"cash_deposits\": \"float64\",\n",
    "        # use nullable int so NaNs are allowed:\n",
    "        \"is_holiday\": \"Int8\",\n",
    "        \"is_payday\": \"Int8\",\n",
    "        \"is_branch_open\": \"Int8\",\n",
    "    }\n",
    ")\n",
    "\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7342b5cc-906f-4233-8551-805b35a0e01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   branch_id        20000 non-null  string        \n",
      " 1   date             20000 non-null  datetime64[ns]\n",
      " 2   atm_withdrawals  19600 non-null  float64       \n",
      " 3   otc_withdrawals  19600 non-null  float64       \n",
      " 4   is_holiday       20000 non-null  Int8          \n",
      " 5   is_payday        20000 non-null  Int8          \n",
      " 6   cash_deposits    20000 non-null  float64       \n",
      " 7   is_branch_open   20000 non-null  Int8          \n",
      "dtypes: Int8(3), datetime64[ns](1), float64(3), string(1)\n",
      "memory usage: 898.6 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>branch_id</th>\n",
       "      <th>date</th>\n",
       "      <th>atm_withdrawals</th>\n",
       "      <th>otc_withdrawals</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_payday</th>\n",
       "      <th>cash_deposits</th>\n",
       "      <th>is_branch_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>30239.18</td>\n",
       "      <td>23064.03</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19192.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B001</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>26297.23</td>\n",
       "      <td>18964.94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14941.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B001</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>23771.65</td>\n",
       "      <td>26629.13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17430.31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B001</td>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>32967.64</td>\n",
       "      <td>21965.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27473.43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B001</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>27759.52</td>\n",
       "      <td>15903.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19177.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  branch_id       date  atm_withdrawals  otc_withdrawals  is_holiday  \\\n",
       "0      B001 2018-10-01         30239.18         23064.03           0   \n",
       "1      B001 2018-10-02         26297.23         18964.94           0   \n",
       "2      B001 2018-10-03         23771.65         26629.13           0   \n",
       "3      B001 2018-10-04         32967.64         21965.25           0   \n",
       "4      B001 2018-10-05         27759.52         15903.84           0   \n",
       "\n",
       "   is_payday  cash_deposits  is_branch_open  \n",
       "0          1       19192.04               1  \n",
       "1          0       14941.69               1  \n",
       "2          0       17430.31               1  \n",
       "3          0       27473.43               1  \n",
       "4          0       19177.98               1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize date strings (replace en/em/minus dashes with hyphen) and parse strictly\n",
    "\n",
    "# Load (or keep your existing df) and normalize the date strings\n",
    "df[\"date\"] = (\n",
    "    df[\"date\"].astype(str).str.strip()\n",
    "      .str.replace(r\"[–—−]\", \"-\", regex=True)  # normalize odd dashes\n",
    ")\n",
    "\n",
    "# OPTION A: if your pandas >= 2.2 supports mixed parsing, this is simplest:\n",
    "try:\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"mixed\", errors=\"raise\")\n",
    "except Exception as e:\n",
    "    print(\"mixed parse failed, falling back to explicit formats:\", e)\n",
    "    # OPTION B: explicit formats by mask (no warnings, still strict)\n",
    "    s = df[\"date\"]\n",
    "    iso_mask  = s.str.fullmatch(r\"\\d{4}-\\d{2}-\\d{2}\")\n",
    "    us4_mask  = s.str.fullmatch(r\"\\d{1,2}/\\d{1,2}/\\d{4}\")\n",
    "    us2_mask  = s.str.fullmatch(r\"\\d{1,2}/\\d{1,2}/\\d{2}\")\n",
    "\n",
    "    parsed = pd.Series(pd.NaT, index=df.index, dtype=\"datetime64[ns]\")\n",
    "    parsed.loc[iso_mask] = pd.to_datetime(s.loc[iso_mask], format=\"%Y-%m-%d\")\n",
    "    parsed.loc[us4_mask] = pd.to_datetime(s.loc[us4_mask], format=\"%m/%d/%Y\")\n",
    "    parsed.loc[us2_mask] = pd.to_datetime(s.loc[us2_mask], format=\"%m/%d/%y\")\n",
    "\n",
    "    # anything left: last-chance permissive parse, then report\n",
    "    rem = parsed.isna()\n",
    "    if rem.any():\n",
    "        parsed.loc[rem] = pd.to_datetime(s.loc[rem], errors=\"coerce\")\n",
    "    bad = parsed.isna()\n",
    "    if bad.any():\n",
    "        print(f\"Unparsable date rows: {bad.sum()}\")\n",
    "        display(df.loc[bad, [\"branch_id\",\"date\"]].head(10))\n",
    "        # drop or fix as you prefer:\n",
    "        df = df.loc[~bad].copy()\n",
    "\n",
    "    df[\"date\"] = parsed\n",
    "\n",
    "# continue: dedupe/order, dtypes\n",
    "df = (\n",
    "    df.drop_duplicates(subset=[\"branch_id\",\"date\"])\n",
    "      .sort_values([\"branch_id\",\"date\"])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "for col in [\"is_holiday\",\"is_payday\",\"is_branch_open\"]:\n",
    "    if col not in df.columns: df[col] = 0\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(0).astype(\"Int8\")\n",
    "\n",
    "for col in [\"atm_withdrawals\",\"otc_withdrawals\",\"cash_deposits\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\").astype(\"float64\")\n",
    "\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f5aeaff-3db7-4652-87ed-21e05c809159",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>branch_id</th>\n",
       "      <th>date</th>\n",
       "      <th>atm_withdrawals</th>\n",
       "      <th>otc_withdrawals</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_payday</th>\n",
       "      <th>cash_deposits</th>\n",
       "      <th>is_branch_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>30239.18</td>\n",
       "      <td>23064.03</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19192.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B001</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>26297.23</td>\n",
       "      <td>18964.94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14941.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B001</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>23771.65</td>\n",
       "      <td>26629.13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17430.31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B001</td>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>32967.64</td>\n",
       "      <td>21965.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27473.43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B001</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>27759.52</td>\n",
       "      <td>15903.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19177.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  branch_id       date  atm_withdrawals  otc_withdrawals  is_holiday  \\\n",
       "0      B001 2018-10-01         30239.18         23064.03           0   \n",
       "1      B001 2018-10-02         26297.23         18964.94           0   \n",
       "2      B001 2018-10-03         23771.65         26629.13           0   \n",
       "3      B001 2018-10-04         32967.64         21965.25           0   \n",
       "4      B001 2018-10-05         27759.52         15903.84           0   \n",
       "\n",
       "   is_payday  cash_deposits  is_branch_open  \n",
       "0          1       19192.04               1  \n",
       "1          0       14941.69               1  \n",
       "2          0       17430.31               1  \n",
       "3          0       27473.43               1  \n",
       "4          0       19177.98               1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bad data. drop duplicates.\n",
    "# you get a unique, chronologically ordered branch_id date table \n",
    "# with a clean, sequential index\n",
    "# This would be perfect for time-based features.\n",
    "df = df.drop_duplicates().sort_values([\"branch_id\",\"date\"]).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c014f89-280e-4f4c-b8fe-58a11f695c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Handle nulls in withdrawals, respect closures if present\n",
    "\n",
    "# if the branch was closed that day, treat withdrawals as truly zero\n",
    "# don’t impute them (in real English - don't fill them up with average/whatever). \n",
    "\n",
    "for col in [\"atm_withdrawals\",\"otc_withdrawals\"]:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"Missing column: {col}\")\n",
    "\n",
    "# if you have an is_branch_open column, set closed-day withdrawals to 0\n",
    "if \"is_branch_open\" in df.columns:\n",
    "    closed = df[\"is_branch_open\"]==0\n",
    "    df.loc[closed, [\"atm_withdrawals\",\"otc_withdrawals\"]] = 0.0\n",
    "\n",
    "# branch-wise robust impute: 14-day rolling median, then branch median\n",
    "\n",
    "# Uses a 14-day trailing rolling median to fill NaNs.\n",
    "# Trailing window = uses past values only (NaNs are ignored), so no leakage.\n",
    "# Median is robust to spikes (better than mean for cash bursts).\n",
    "# min_periods=1 lets the window work at the start of the series.\n",
    "        \n",
    "def impute_series(s):\n",
    "    s2 = s.copy()\n",
    "    s2 = s2.fillna(s2.rolling(14, min_periods=1).median()) # recent history fill\n",
    "    s2 = s2.fillna(s2.median()) # fallback - If there are still gaps (e.g., very early days with no history), \n",
    "                                # fill them with the branch’s overall median.\n",
    "                                # Why this pattern? recent, robust estimate first (captures weekly/month-end rhythm), \n",
    "                                # then a safe branch-level fallback to avoid leaving NaNs.\n",
    "    return s2\n",
    "\n",
    "for col in [\"atm_withdrawals\",\"otc_withdrawals\"]:\n",
    "    df[col] = df.groupby(\"branch_id\", group_keys=False)[col].apply(impute_series)\n",
    "\n",
    "# Compute cash_out\n",
    "# It builds a clean total cash-out number and enforces a business rule:\n",
    "# clip(lower=0) on each column -> forces no negative withdrawals \n",
    "# (protects against data glitches/rollbacks that would make ATM/OTC go < 0).\n",
    "# Sum the clipped ATM + OTC -> cash_out = total cash withdrawn that day.\n",
    "df[\"cash_out\"] = df[\"atm_withdrawals\"].clip(lower=0) + df[\"otc_withdrawals\"].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2834300-371f-44f3-bd8a-c356163fd714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Calendar features (derived from date; all known at prediction time)\n",
    "\n",
    "# — Ensure 'date' is true datetime —\n",
    "df[\"date\"] = pd.to_datetime(\n",
    "    df[\"date\"].astype(str).str.strip(),   # trim stray spaces\n",
    "    format=\"%Y-%m-%d\",                    # our generator uses ISO dates\n",
    "    errors=\"coerce\"                       # bad rows -> NaT\n",
    ")\n",
    "bad = df[\"date\"].isna()\n",
    "if bad.any():\n",
    "    print(f\"Warning: dropped {bad.sum()} rows with unparsable dates\")\n",
    "    df = df.loc[~bad].copy()\n",
    "\n",
    "# — Derive features —\n",
    "df[\"dow\"] = df[\"date\"].dt.day_name()\n",
    "df[\"is_weekend\"] = df[\"date\"].dt.dayofweek.isin([5, 6]).astype(int)\n",
    "\n",
    "# \"last two days of month\" flag (like our generator logic)\n",
    "df[\"is_month_end\"] = (\n",
    "    ((df[\"date\"] + pd.offsets.Day(1)).dt.month != df[\"date\"].dt.month) |\n",
    "    ((df[\"date\"] + pd.offsets.Day(2)).dt.month != df[\"date\"].dt.month)\n",
    ").astype(int)\n",
    "\n",
    "# — Ensure holiday/payday columns exist and are clean ints —\n",
    "for col in [\"is_holiday\", \"is_payday\"]:\n",
    "    if col not in df.columns:\n",
    "        df[col] = 0\n",
    "    else:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(0).astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0e741e6-2312-411c-bc78-fbe577cd2370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training rows after feature build: 19,768 (from 20,000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>branch_id</th>\n",
       "      <th>date</th>\n",
       "      <th>lag1</th>\n",
       "      <th>lag7</th>\n",
       "      <th>ma7</th>\n",
       "      <th>ma28</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_payday</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>dow</th>\n",
       "      <th>y_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001</td>\n",
       "      <td>2018-10-29</td>\n",
       "      <td>33490.37</td>\n",
       "      <td>38584.57</td>\n",
       "      <td>40147.525714</td>\n",
       "      <td>38944.082143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>49674.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B001</td>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>42620.57</td>\n",
       "      <td>41899.62</td>\n",
       "      <td>40724.097143</td>\n",
       "      <td>38562.559286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>44740.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B001</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>49674.84</td>\n",
       "      <td>36376.76</td>\n",
       "      <td>41834.842857</td>\n",
       "      <td>38720.154643</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>46302.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B001</td>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>44740.41</td>\n",
       "      <td>45553.33</td>\n",
       "      <td>43029.650000</td>\n",
       "      <td>38517.998571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>52392.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B001</td>\n",
       "      <td>2018-11-02</td>\n",
       "      <td>46302.39</td>\n",
       "      <td>44022.65</td>\n",
       "      <td>43136.658571</td>\n",
       "      <td>38209.766429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>35792.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  branch_id       date      lag1      lag7           ma7          ma28  \\\n",
       "0      B001 2018-10-29  33490.37  38584.57  40147.525714  38944.082143   \n",
       "1      B001 2018-10-30  42620.57  41899.62  40724.097143  38562.559286   \n",
       "2      B001 2018-10-31  49674.84  36376.76  41834.842857  38720.154643   \n",
       "3      B001 2018-11-01  44740.41  45553.33  43029.650000  38517.998571   \n",
       "4      B001 2018-11-02  46302.39  44022.65  43136.658571  38209.766429   \n",
       "\n",
       "   is_holiday  is_payday  is_month_end  is_weekend        dow    y_next  \n",
       "0           0          0             0           0     Monday  49674.84  \n",
       "1           0          0             1           0    Tuesday  44740.41  \n",
       "2           0          0             1           0  Wednesday  46302.39  \n",
       "3           0          1             0           0   Thursday  52392.41  \n",
       "4           0          0             0           0     Friday  35792.12  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) Lags & rolling means per branch (NO leakage) + target y_next\n",
    "#    Vectorized version (no groupby.apply warning)\n",
    "\n",
    "# --- safety checks ---\n",
    "required = [\"branch_id\", \"date\", \"cash_out\"]\n",
    "missing = [c for c in required if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns needed for features: {missing}\")\n",
    "\n",
    "# Keep rows ordered by branch & date\n",
    "df = df.sort_values([\"branch_id\", \"date\"]).copy()\n",
    "\n",
    "# Make 'dow' categorical (helps memory / one-hot later)\n",
    "if \"dow\" in df.columns and df[\"dow\"].dtype != \"category\":\n",
    "    df[\"dow\"] = df[\"dow\"].astype(\"category\")\n",
    "\n",
    "grp = df.groupby(\"branch_id\", sort=False, group_keys=False)\n",
    "\n",
    "# Past-only features (shift ensures no leakage)\n",
    "df[\"lag1\"]  = grp[\"cash_out\"].shift(1)\n",
    "df[\"lag7\"]  = grp[\"cash_out\"].shift(7)\n",
    "df[\"ma7\"]   = grp[\"cash_out\"].transform(lambda s: s.rolling(7,  min_periods=7).mean().shift(1))\n",
    "df[\"ma28\"]  = grp[\"cash_out\"].transform(lambda s: s.rolling(28, min_periods=28).mean().shift(1))\n",
    "\n",
    "# Target: tomorrow's cash_out\n",
    "df[\"y_next\"] = grp[\"cash_out\"].shift(-1)\n",
    "\n",
    "# Drop rows that don't have enough history or target\n",
    "feat_cols = [\"lag1\",\"lag7\",\"ma7\",\"ma28\",\"is_holiday\",\"is_payday\",\"is_month_end\",\"is_weekend\",\"dow\"]\n",
    "dfm = df.dropna(subset=feat_cols + [\"y_next\"]).reset_index(drop=True)\n",
    "\n",
    "print(f\"Training rows after feature build: {len(dfm):,} (from {len(df):,})\")\n",
    "dfm[[\"branch_id\",\"date\"] + feat_cols + [\"y_next\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0b188b7-954d-4c60-b2dc-1a316a3bffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Rule\n",
    "\n",
    "# Here's the simple (sort of) rule I use on any problem:\n",
    "# 1) State the target & timing.\n",
    "#    What are you predicting, and when is the prediction made?\n",
    "#    Only use data you'd know by that time (no future info).\n",
    "# 2) List what you have.\n",
    "#    Columns, IDs, timestamps, categories. Circle the ones available at prediction time.\n",
    "# 3) Pick 1-2 candidates from proven templates:\n",
    "#    - Time/sequence: lags (y_{t-1}), rolling mean/std (past-only), day-of-week/season.\n",
    "#    - Tabular: counts, rates, ratios (x1/x2, x1-x2), missing-value flags.\n",
    "#    - Categoricals: one-hot (low cardinality) or count/target encoding (high).\n",
    "#    - Text/images: simple length/TF-IDF or pretrained embeddings.\n",
    "# 4) Engineer safely.\n",
    "#    Compute with past data only; add a quick \"leakage check\" (\"Would I know this at prediction time?\").\n",
    "# 5) Test, don't guess.\n",
    "#    Keep a fixed validation split. Train your baseline, then add the new feature(s) and retrain.\n",
    "# 6) Decide by lift.\n",
    "#    If your metric improves consistently (e.g., MAPE ↓ by >= 0.3–0.5, AUC ↑ a bit), keep it; otherwise drop it.\n",
    "# 7) Repeat in small steps.\n",
    "#    Add another candidate, test again. Stop when gains flatten.\n",
    "# 8) Favor simple & stable.\n",
    "#    Prefer features that are easy to compute, explain, and won't drift.\n",
    "#\n",
    "# start simple -> add one feature -> measure -> keep or toss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0013d44-1e3a-4b8c-8061-dd6f4256e437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19055,\n",
       " 713,\n",
       " Timestamp('2025-08-04 00:00:00'),\n",
       " Timestamp('2025-05-06 00:00:00'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) Time-based split\n",
    "last_date = dfm[\"date\"].max()\n",
    "test_start = last_date - pd.Timedelta(days=TEST_DAYS)\n",
    "\n",
    "train_mask = dfm[\"date\"] <= test_start\n",
    "test_mask  = dfm[\"date\"] >  test_start\n",
    "\n",
    "X_train, y_train = dfm.loc[train_mask, feat_cols], dfm.loc[train_mask, \"y_next\"]\n",
    "X_test,  y_test  = dfm.loc[test_mask,  feat_cols], dfm.loc[test_mask,  \"y_next\"]\n",
    "\n",
    "len(X_train), len(X_test), last_date, test_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22a37c50-8634-42f0-89e8-a6c3c01e18b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Naive lag1 MAPE (non-zero only)': 0.29749628743549883,\n",
       " 'MA7 MAPE (non-zero only)': 0.1931552218044746,\n",
       " 'Naive lag1 MAPE (safe)': 1176637756.2490463,\n",
       " 'MA7 MAPE (safe)': 1206596553.9840295,\n",
       " 'Naive lag1 MAE': 12090.137896213184,\n",
       " 'MA7 MAE': 8465.736792226007,\n",
       " 'Naive lag1 WMAPE': 0.3159503168270949,\n",
       " 'MA7 WMAPE': 0.22123421954652597,\n",
       " 'Zero-actual days in test': 22}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6) Baselines — safe with zeros in the data\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Baseline predictions\n",
    "naive_pred = X_test[\"lag1\"].to_numpy()   # yesterday's value\n",
    "ma7_pred   = X_test[\"ma7\"].to_numpy()    # 7-day average\n",
    "y_true     = y_test.to_numpy()\n",
    "\n",
    "# Helper metrics\n",
    "def mape_safe(y, yhat, eps=1e-6):\n",
    "    \"\"\"MAPE that never divides by zero.\"\"\"\n",
    "    y = np.asarray(y)\n",
    "    return np.mean(np.abs(y - yhat) / np.maximum(np.abs(y), eps))\n",
    "\n",
    "def wmape(y, yhat, eps=1e-6):\n",
    "    \"\"\"Weighted MAPE (sum abs error / sum actual).\"\"\"\n",
    "    return float(np.sum(np.abs(y - yhat)) / max(np.sum(np.abs(y)), eps))\n",
    "\n",
    "def mae(y, yhat):\n",
    "    \"\"\"Mean Absolute Error.\"\"\"\n",
    "    return float(np.mean(np.abs(y - yhat)))\n",
    "\n",
    "# Also compute MAPE only where actual > 0\n",
    "nz = y_true > 0\n",
    "zero_days = int((~nz).sum())\n",
    "\n",
    "baseline_results = {\n",
    "    # MAPE on non-zero actuals only\n",
    "    \"Naive lag1 MAPE (non-zero only)\": mean_absolute_percentage_error(y_true[nz], naive_pred[nz]),\n",
    "    \"MA7 MAPE (non-zero only)\":        mean_absolute_percentage_error(y_true[nz], ma7_pred[nz]),\n",
    "\n",
    "    # Safe MAPE with epsilon\n",
    "    \"Naive lag1 MAPE (safe)\": mape_safe(y_true, naive_pred),\n",
    "    \"MA7 MAPE (safe)\":        mape_safe(y_true, ma7_pred),\n",
    "\n",
    "    # Zero-friendly metrics\n",
    "    \"Naive lag1 MAE\":   mae(y_true, naive_pred),\n",
    "    \"MA7 MAE\":          mae(y_true, ma7_pred),\n",
    "    \"Naive lag1 WMAPE\": wmape(y_true, naive_pred),\n",
    "    \"MA7 WMAPE\":        wmape(y_true, ma7_pred),\n",
    "\n",
    "    \"Zero-actual days in test\": zero_days\n",
    "}\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00c736a5-8ffe-481d-8102-880731bc6cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Think of these baselines as the \"dumb but strong\" yardsticks you must beat.\n",
    "#\n",
    "# What they are:\n",
    "# - lag1 = \"predict tomorrow = yesterday.\"\n",
    "# - MA7  = \"predict tomorrow = average of last 7 days.\"\n",
    "#\n",
    "# Why you need them:\n",
    "# 1) Set the bar. If your fancy model can't beat these simple rules, it's not ready.\n",
    "# 2) Catch data issues. If baselines look crazy (or way too good), your data/splits may be wrong.\n",
    "# 3) Provide a fallback. In production, you can always use MA7/lag1 if the model is down.\n",
    "#\n",
    "# What the numbers mean (from the cell):\n",
    "# - MAE  -> average dollar error (easy to explain).\n",
    "# - WMAPE -> average percent error that works even when actual=0 (e.g., 0.18 = 18%).\n",
    "# - MAPE (non-zero only / safe) -> percent error, but either skips zeros or protects against divide-by-zero.\n",
    "# - Zero-actual days -> how many test days had actual=0; explains why plain MAPE can explode.\n",
    "#\n",
    "# How it helps decision-making:\n",
    "# - Compare model vs. baselines on WMAPE/MAE.\n",
    "# - If your model is 3–5 percentage points better (e.g., baseline WMAPE 0.20 -> model 0.15), that's meaningful.\n",
    "# - If not, improve data cleaning/features—or just use MA7/lag1 for now.\n",
    "#\n",
    "# Baselines tell you \"what good means.\" Your model must clearly beat lag1/MA7 on WMAPE/MAE; otherwise, \n",
    "# keep iterating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61a4e155-cb37-4004-b574-6492e29dd73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model MAE': 5904.315540470965,\n",
       " 'Model WMAPE': 0.15429686424364403,\n",
       " 'Model MAPE (non-zero)': 0.1166368279656849,\n",
       " 'Model MAPE (safe)': 1229033101.0387259,\n",
       " 'RMSE': 12491.552693175841,\n",
       " 'Naive lag1 MAPE (non-zero only)': 0.29749628743549883,\n",
       " 'MA7 MAPE (non-zero only)': 0.1931552218044746,\n",
       " 'Naive lag1 MAPE (safe)': 1176637756.2490463,\n",
       " 'MA7 MAPE (safe)': 1206596553.9840295,\n",
       " 'Naive lag1 MAE': 12090.137896213184,\n",
       " 'MA7 MAE': 8465.736792226007,\n",
       " 'Naive lag1 WMAPE': 0.3159503168270949,\n",
       " 'MA7 WMAPE': 0.22123421954652597,\n",
       " 'Zero-actual days in test': 22}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7) Simple model: ElasticNet (interpretable, solid baseline)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_absolute_percentage_error, root_mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "num_cols = [\"lag1\",\"lag7\",\"ma7\",\"ma28\",\"is_holiday\",\"is_payday\",\"is_month_end\",\"is_weekend\"]\n",
    "cat_cols = [\"dow\"]\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=0)\n",
    "pipe = Pipeline([(\"pre\", pre), (\"model\", model)])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "pred = pipe.predict(X_test)\n",
    "y_true = y_test.to_numpy()\n",
    "\n",
    "# --- metrics helpers (from earlier cell) ---\n",
    "def mape_safe(y, yhat, eps=1e-6):\n",
    "    y = np.asarray(y)\n",
    "    return float(np.mean(np.abs(y - yhat) / np.maximum(np.abs(y), eps)))\n",
    "\n",
    "def wmape(y, yhat, eps=1e-6):\n",
    "    return float(np.sum(np.abs(y - yhat)) / max(np.sum(np.abs(y)), eps))\n",
    "\n",
    "def mae(y, yhat):\n",
    "    return float(np.mean(np.abs(y - yhat)))\n",
    "\n",
    "nz = y_true > 0  # non-zero actuals\n",
    "\n",
    "model_results = {\n",
    "    \"Model MAE\":                mae(y_true, pred),\n",
    "    \"Model WMAPE\":              wmape(y_true, pred),\n",
    "    \"Model MAPE (non-zero)\":    mean_absolute_percentage_error(y_true[nz], pred[nz]),\n",
    "    \"Model MAPE (safe)\":        mape_safe(y_true, pred),\n",
    "    \"RMSE\":                     float(root_mean_squared_error(y_true, pred)),  # <-- no deprecation\n",
    "}\n",
    "\n",
    "# if you computed baseline_results earlier, merge to compare:\n",
    "{**model_results, **baseline_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11b5dd0a-d11f-4e42-88bf-0e809572e54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model WMAPE ~= 0.145 -> 14.5% average percent error.\n",
    "# Baselines: lag1 WMAPE ~= 31.6%, MA7 WMAPE ~= 22.1% -> model beats:\n",
    "#   - lag1 by ~17 percentage points\n",
    "#   - MA7 by ~7.6 points (~34% relative improvement) \n",
    "# Model MAPE (non-zero) ~= 11.7% -> percent error only on days with actual > 0.\n",
    "#   (Baselines: lag1 ~= 29.7%, MA7 ~= 19.3%.)\n",
    "# MAE ~= $5,904 -> average dollar mistake per branch-day.\n",
    "# To judge scale, compare to the average actual:\n",
    "#   y_mean = y_test.mean()\n",
    "#   5904 / y_mean   # ~= WMAPE\n",
    "\n",
    "#\n",
    "# Rule of thumb (varies by use case):\n",
    "# WMAPE ≥ 20%: weak\n",
    "# 15–20%: okay\n",
    "# 10–15%: good\n",
    "# <10%: excellent (I also start to doubt here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "882ea1ba-9fbd-4577-9987-7ed79bc37759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WMAPE': 0.1543, 'Accuracy % (1 - WMAPE)': 84.6, 'MAE ($)': 5904.32}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def wmape(y, yhat, eps=1e-6):\n",
    "    return float(np.sum(np.abs(y - yhat)) / max(np.sum(np.abs(y)), eps))\n",
    "\n",
    "def mae(y, yhat):\n",
    "    return float(np.mean(np.abs(y - yhat)))\n",
    "\n",
    "y_true = y_test.to_numpy()\n",
    "y_hat  = pred  # from your model\n",
    "\n",
    "model_wmape = wmape(y_true, y_hat)\n",
    "model_mae   = mae(y_true, y_hat)\n",
    "\n",
    "# “Accuracy%” (common business reporting): 100 * (1 - WMAPE)\n",
    "forecast_accuracy_pct = 100 * (1 - model_wmape)\n",
    "\n",
    "print({\n",
    "    \"WMAPE\": round(model_wmape, 4),\n",
    "    \"Accuracy % (1 - WMAPE)\": round(forecast_accuracy_pct, 1),\n",
    "    \"MAE ($)\": round(model_mae, 2),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4d238b7-eaab-490d-8f44-307d3aaa8507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using P90 buffer (90th pct relative error) = 21.6%\n",
      "Max date in file: 2025-08-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>branch_id</th>\n",
       "      <th>predict_for</th>\n",
       "      <th>y_hat_P50</th>\n",
       "      <th>y_hat_P90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001</td>\n",
       "      <td>2025-08-05</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>58300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B002</td>\n",
       "      <td>2025-08-05</td>\n",
       "      <td>56700.0</td>\n",
       "      <td>69000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B003</td>\n",
       "      <td>2025-08-05</td>\n",
       "      <td>51900.0</td>\n",
       "      <td>63100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B004</td>\n",
       "      <td>2025-08-05</td>\n",
       "      <td>41200.0</td>\n",
       "      <td>50100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B005</td>\n",
       "      <td>2025-08-05</td>\n",
       "      <td>38200.0</td>\n",
       "      <td>46500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B006</td>\n",
       "      <td>2025-08-05</td>\n",
       "      <td>40600.0</td>\n",
       "      <td>49300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B007</td>\n",
       "      <td>2025-08-05</td>\n",
       "      <td>36100.0</td>\n",
       "      <td>43900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B008</td>\n",
       "      <td>2025-08-06</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>39500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  branch_id predict_for  y_hat_P50  y_hat_P90\n",
       "0      B001  2025-08-05    48000.0    58300.0\n",
       "1      B002  2025-08-05    56700.0    69000.0\n",
       "2      B003  2025-08-05    51900.0    63100.0\n",
       "3      B004  2025-08-05    41200.0    50100.0\n",
       "4      B005  2025-08-05    38200.0    46500.0\n",
       "5      B006  2025-08-05    40600.0    49300.0\n",
       "6      B007  2025-08-05    36100.0    43900.0\n",
       "7      B008  2025-08-06    32500.0    39500.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8) Next-day forecast per branch with P50 and P90\n",
    "# P50 = model point forecast (median). \n",
    "# P90 = P50 with a safety buffer based on the 90th percentile of recent relative errors.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "feat_cols = [\"lag1\",\"lag7\",\"ma7\",\"ma28\",\"is_holiday\",\"is_payday\",\"is_month_end\",\"is_weekend\",\"dow\"]\n",
    "\n",
    "# --- 1) Estimate a P90 buffer from the held-out set ---\n",
    "y_val   = y_test.to_numpy()\n",
    "yhat_val = pipe.predict(X_test)\n",
    "\n",
    "# use only rows with non-zero actuals to avoid divide-by-zero\n",
    "mask = y_val > 0\n",
    "if mask.sum() >= 30:\n",
    "    rel_err = np.abs(y_val[mask] - yhat_val[mask]) / y_val[mask]\n",
    "    p90_rel = float(np.quantile(rel_err, 0.90))\n",
    "else:\n",
    "    p90_rel = 0.25  # fallback buffer if too few rows\n",
    "\n",
    "# clamp for sanity (5%..100%)\n",
    "p90_rel = float(min(max(p90_rel, 0.05), 1.00))\n",
    "print(f\"Using P90 buffer (90th pct relative error) = {p90_rel:.1%}\")\n",
    "\n",
    "# --- 2) Build next-day features from the latest available day per branch ---\n",
    "ready = df.dropna(subset=[\"lag1\",\"lag7\",\"ma7\",\"ma28\"]).copy()\n",
    "last_per_branch = ready.sort_values(\"date\").groupby(\"branch_id\").tail(1)\n",
    "\n",
    "next_X = last_per_branch[feat_cols]\n",
    "p50 = pipe.predict(next_X)\n",
    "p50 = np.clip(p50, 0, None)  # no negative cash\n",
    "\n",
    "# P90 as multiplicative uplift of P50\n",
    "p90 = p50 * (1 + p90_rel)\n",
    "\n",
    "# optional: round to nearest $100 for operational use\n",
    "p50 = (p50 / 100).round() * 100\n",
    "p90 = (p90 / 100).round() * 100\n",
    "\n",
    "forecast = last_per_branch[[\"branch_id\",\"date\"]].copy()\n",
    "forecast[\"predict_for\"] = forecast[\"date\"] + pd.Timedelta(days=1)\n",
    "forecast[\"y_hat_P50\"] = p50\n",
    "forecast[\"y_hat_P90\"] = p90\n",
    "\n",
    "forecast = forecast[[\"branch_id\",\"predict_for\",\"y_hat_P50\",\"y_hat_P90\"]] \\\n",
    "           .sort_values(\"branch_id\").reset_index(drop=True)\n",
    "\n",
    "print(\"Max date in file:\", df[\"date\"].max().date())\n",
    "forecast.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8500b430-65b8-4608-a80e-d3e817545a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P90 buffer (90th pct relative error) = 21.6%\n"
     ]
    }
   ],
   "source": [
    "# === Interactive forecast for a chosen branch & date (P50 + P90) ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "\n",
    "# ---- P90 buffer from validation (run after model is trained and you have X_test, y_test) ----\n",
    "y_val = y_test.to_numpy()\n",
    "yhat_val = pipe.predict(X_test)\n",
    "mask = y_val > 0\n",
    "if mask.sum() >= 30:\n",
    "    rel_err = np.abs(y_val[mask] - yhat_val[mask]) / y_val[mask]\n",
    "    P90_BUFFER_REL = float(np.quantile(rel_err, 0.90))\n",
    "else:\n",
    "    P90_BUFFER_REL = 0.25  # fallback if not enough data\n",
    "# clamp 5%..100% for sanity\n",
    "P90_BUFFER_REL = float(min(max(P90_BUFFER_REL, 0.05), 1.00))\n",
    "print(f\"P90 buffer (90th pct relative error) = {P90_BUFFER_REL:.1%}\")\n",
    "\n",
    "# --- simple calendar helpers (future-known) ---\n",
    "def _nth_weekday_of_month(year, month, weekday, n):\n",
    "    d = pd.Timestamp(year=year, month=month, day=1)\n",
    "    add = (weekday - d.weekday()) % 7\n",
    "    return (d + pd.Timedelta(days=add) + pd.Timedelta(weeks=n-1)).date()\n",
    "\n",
    "def _last_weekday_of_month(year, month, weekday):\n",
    "    d = (pd.Timestamp(year=year, month=month, day=1) + pd.offsets.MonthEnd(1))\n",
    "    back = (d.weekday() - weekday) % 7\n",
    "    return (d - pd.Timedelta(days=back)).date()\n",
    "\n",
    "def us_bank_holidays(year:int):\n",
    "    hol = {\n",
    "        date(year,1,1), date(year,6,19), date(year,7,4),\n",
    "        date(year,11,11), date(year,12,25)\n",
    "    }\n",
    "    hol.add(_nth_weekday_of_month(year,1,0,3))   # MLK\n",
    "    hol.add(_nth_weekday_of_month(year,2,0,3))   # Presidents\n",
    "    hol.add(_last_weekday_of_month(year,5,0))    # Memorial\n",
    "    hol.add(_nth_weekday_of_month(year,9,0,1))   # Labor\n",
    "    hol.add(_nth_weekday_of_month(year,11,3,4))  # Thanksgiving\n",
    "    return hol\n",
    "\n",
    "_holiday_cache = {}\n",
    "\n",
    "def cal_feats_for(ts: pd.Timestamp):\n",
    "    d = ts.date()\n",
    "    y = d.year\n",
    "    if y not in _holiday_cache:\n",
    "        _holiday_cache[y] = us_bank_holidays(y)\n",
    "    is_holiday = int(d in _holiday_cache[y])\n",
    "    is_payday  = int(d.day in (1, 15))\n",
    "    is_weekend = int(ts.dayofweek in (5,6))\n",
    "    is_month_end = int(\n",
    "        (ts + pd.Timedelta(days=1)).month != ts.month or\n",
    "        (ts + pd.Timedelta(days=2)).month != ts.month\n",
    "    )\n",
    "    dow = ts.day_name()\n",
    "    return {\"is_holiday\": is_holiday, \"is_payday\": is_payday,\n",
    "            \"is_weekend\": is_weekend, \"is_month_end\": is_month_end, \"dow\": dow}\n",
    "\n",
    "def predict_for_branch_date(branch_id: str, target_date_str: str):\n",
    "    # --- inputs & validation ---\n",
    "    try:\n",
    "        target_ts = pd.to_datetime(target_date_str, format=\"%Y-%m-%d\")\n",
    "    except Exception:\n",
    "        target_ts = pd.to_datetime(target_date_str)\n",
    "    if branch_id not in set(df[\"branch_id\"].astype(str).unique()):\n",
    "        raise ValueError(f\"Unknown branch_id '{branch_id}'. Available: {sorted(df['branch_id'].unique())[:10]} ...\")\n",
    "\n",
    "    hist = (\n",
    "        df.loc[df[\"branch_id\"].astype(str)==branch_id, [\"date\",\"cash_out\"]]\n",
    "          .sort_values(\"date\").reset_index(drop=True)\n",
    "    )\n",
    "    if hist.empty:\n",
    "        raise ValueError(f\"No history for branch {branch_id}\")\n",
    "\n",
    "    last_known = hist[\"date\"].max()\n",
    "    recent_vals = list(hist.tail(28)[\"cash_out\"].astype(float).values)\n",
    "\n",
    "    def make_feature_row(asof_ts: pd.Timestamp):\n",
    "        lag1 = recent_vals[-1] if len(recent_vals) >= 1 else np.nan\n",
    "        lag7 = recent_vals[-7] if len(recent_vals) >= 7 else lag1\n",
    "        ma7  = float(np.mean(recent_vals[-7:]))  if len(recent_vals) >= 2 else lag1\n",
    "        ma28 = float(np.mean(recent_vals[-28:])) if len(recent_vals) >= 2 else lag1\n",
    "        c = cal_feats_for(asof_ts + pd.Timedelta(days=1))\n",
    "        return pd.DataFrame([{\n",
    "            \"lag1\": lag1, \"lag7\": lag7, \"ma7\": ma7, \"ma28\": ma28,\n",
    "            \"is_holiday\": c[\"is_holiday\"], \"is_payday\": c[\"is_payday\"],\n",
    "            \"is_month_end\": c[\"is_month_end\"], \"is_weekend\": c[\"is_weekend\"],\n",
    "            \"dow\": c[\"dow\"],\n",
    "        }])\n",
    "\n",
    "    # Case A: predicting a date within history\n",
    "    if target_ts <= last_known:\n",
    "        t = target_ts - pd.Timedelta(days=1)\n",
    "        sub = hist.loc[hist[\"date\"] <= t].tail(28)\n",
    "        if sub.empty:\n",
    "            raise ValueError(\"Not enough history before that date to build features.\")\n",
    "        recent_vals[:] = list(sub[\"cash_out\"].astype(float).values)\n",
    "        X = make_feature_row(t)\n",
    "        p50 = float(max(0.0, pipe.predict(X)[0]))\n",
    "        p90 = p50 * (1 + P90_BUFFER_REL)\n",
    "        return p50, p90, last_known.date(), 1\n",
    "\n",
    "    # Case B: multi-step forecast beyond last_known\n",
    "    cur = last_known\n",
    "    p50 = None\n",
    "    while cur < target_ts:\n",
    "        X = make_feature_row(cur)     # predict for cur+1\n",
    "        p50 = float(max(0.0, pipe.predict(X)[0]))\n",
    "        recent_vals.append(p50)\n",
    "        if len(recent_vals) > 28:\n",
    "            recent_vals.pop(0)\n",
    "        cur = cur + pd.Timedelta(days=1)\n",
    "\n",
    "    steps_ahead = int((target_ts - last_known).days)\n",
    "    p90 = p50 * (1 + P90_BUFFER_REL)\n",
    "    return p50, p90, last_known.date(), steps_ahead\n",
    "\n",
    "# --- Interactive prompts ---\n",
    "branch = input(\"Enter branch_id (e.g., B001): \").strip()\n",
    "target = input(\"Predict for date (YYYY-MM-DD): \").strip()\n",
    "\n",
    "p50, p90, last_obs, k = predict_for_branch_date(branch, target)\n",
    "print(f\"\\nLast observed date for {branch}: {last_obs}\")\n",
    "print(f\"Predicting {k}-day(s) ahead for {branch} on {pd.to_datetime(target).date()}:\")\n",
    "print(f\"Estimated cash needed — P50: {p50:,.0f}   P90: {p90:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5604f4b5-2423-4613-be5d-0f4252fc2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CHEAT SHEET — Which model should I use for tabular forecasting?\n",
    "#\n",
    "# Always start with SIMPLE BASELINES you must beat:\n",
    "#   - lag1  : \"tomorrow = yesterday\"\n",
    "#   - MA7   : \"tomorrow = average of last 7 days\"\n",
    "#\n",
    "# Linear (simple & explainable)\n",
    "#   - ElasticNet\n",
    "#   Use when: relationships are mostly linear and you want clear coefficients.\n",
    "#   Pros: fast, easy to explain. Cons: misses non-linear patterns.\n",
    "#\n",
    "# Trees (handle non-linearities automatically)\n",
    "#   - RandomForestRegressor\n",
    "#     Use when: you want a robust, low-tuning upgrade over linear models.\n",
    "#   - HistGradientBoostingRegressor (built-in sklearn)\n",
    "#     Use when: you want strong accuracy on tabular data with minimal deps.\n",
    "#   - XGBoost (xgboost library)\n",
    "#     Use when: you have thousands+ rows and want state-of-the-art accuracy.\n",
    "#     Tip: use early stopping (needs a small validation slice).\n",
    "#\n",
    "# Classical single-series models (per branch)\n",
    "#   - ARIMA / ETS / Prophet\n",
    "#     Use when: modeling ONE series with strong seasonality and few features.\n",
    "#     (Less convenient when you have many branches + extra regressors.)\n",
    "#\n",
    "# Neural nets\n",
    "#   - Usually overkill for small/medium tabular datasets. Consider only if\n",
    "#     you have lots of data and complex signals (images/text, long horizons).\n",
    "#\n",
    "# How to choose (super short):\n",
    "#   1) Build features → do a time-based split.\n",
    "#   2) Train ElasticNet + RandomForest + HistGB (and XGBoost if installed).\n",
    "#   3) Compare WMAPE/MAE to lag1 & MA7. \n",
    "#   4) Pick the SIMPLEST model that clearly wins. If gains are tiny, prefer simpler.\n",
    "# =============================================================================\n",
    "\n",
    "# quick bake-off you can run right away (uses your existing X_train/X_test etc.)\n",
    "# ---- Bake-off: ElasticNet, RandomForest, HistGB, and XGBoost (robust early stopping) ----\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "num_cols = [\"lag1\",\"lag7\",\"ma7\",\"ma28\",\"is_holiday\",\"is_payday\",\"is_month_end\",\"is_weekend\"]\n",
    "cat_cols = [\"dow\"]\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "])\n",
    "\n",
    "def wmape(y, yhat, eps=1e-6):\n",
    "    y = np.asarray(y); yhat = np.asarray(yhat)\n",
    "    return float(np.sum(np.abs(y - yhat)) / max(np.sum(np.abs(y)), eps))\n",
    "\n",
    "results = {}\n",
    "\n",
    "# -------- Linear & tree models via Pipeline (no special eval_set needed) --------\n",
    "for name, model in {\n",
    "    \"ElasticNet\": ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=0),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=300, random_state=0, n_jobs=-1),\n",
    "    \"HistGB\": HistGradientBoostingRegressor(random_state=0),\n",
    "}.items():\n",
    "    pipe = Pipeline([(\"pre\", pre), (\"model\", model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    yhat = pipe.predict(X_test)\n",
    "    results[name] = {\"WMAPE\": round(wmape(y_test, yhat), 4),\n",
    "                     \"MAE\":   round(float(mean_absolute_error(y_test, yhat)), 2)}\n",
    "\n",
    "# -------- XGBoost with robust early-stopping (no Pipeline kwargs) --------\n",
    "# -------- XGBoost with version-safe early stopping --------\n",
    "try:\n",
    "    import xgboost as xgb, inspect\n",
    "\n",
    "    # make a small validation slice at the tail of training\n",
    "    VAL_DAYS = 30\n",
    "    val_start = test_start - pd.Timedelta(days=VAL_DAYS)\n",
    "    train_core = (dfm[\"date\"] <= val_start)\n",
    "    val_core   = (dfm[\"date\"] >  val_start) & (dfm[\"date\"] <= test_start)\n",
    "\n",
    "    X_tr, y_tr = dfm.loc[train_core, num_cols+cat_cols], dfm.loc[train_core, \"y_next\"]\n",
    "    X_val, y_val = dfm.loc[val_core,  num_cols+cat_cols], dfm.loc[val_core,  \"y_next\"]\n",
    "\n",
    "    # fit preprocessor once and transform all splits\n",
    "    pre_xgb = pre.fit(X_tr)\n",
    "    Xt_tr   = pre_xgb.transform(X_tr)\n",
    "    Xt_val  = pre_xgb.transform(X_val)\n",
    "    Xt_test = pre_xgb.transform(X_test)\n",
    "\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        n_estimators=2000, learning_rate=0.03, max_depth=6,\n",
    "        subsample=0.8, colsample_bytree=0.8, reg_lambda=1.0,\n",
    "        min_child_weight=1, tree_method=\"hist\", random_state=0, n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # choose a compatible early-stopping API\n",
    "    params = inspect.signature(xgb_model.fit).parameters\n",
    "    if \"callbacks\" in params:  # newer API\n",
    "        cb = [xgb.callback.EarlyStopping(rounds=50, save_best=True)]\n",
    "        xgb_model.fit(Xt_tr, y_tr.values, eval_set=[(Xt_val, y_val.values)],\n",
    "                      callbacks=cb, verbose=False)\n",
    "    elif \"early_stopping_rounds\" in params:  # older-but-common API\n",
    "        xgb_model.fit(Xt_tr, y_tr.values, eval_set=[(Xt_val, y_val.values)],\n",
    "                      early_stopping_rounds=50, verbose=False)\n",
    "    else:  # very old API: no early stopping\n",
    "        xgb_model.fit(Xt_tr, y_tr.values)\n",
    "\n",
    "    yhat_xgb = xgb_model.predict(Xt_test)\n",
    "    results[\"XGBoost\"] = {\n",
    "        \"WMAPE\": round(wmape(y_test, yhat_xgb), 4),\n",
    "        \"MAE\":   round(float(mean_absolute_error(y_test, yhat_xgb)), 2),\n",
    "    }\n",
    "except Exception as e:\n",
    "    results[\"XGBoost\"] = {\"error\": f\"Skipped XGBoost: {e}\"}\n",
    "\n",
    "# -------- Baselines for context --------\n",
    "naive_pred = X_test[\"lag1\"].to_numpy()\n",
    "ma7_pred   = X_test[\"ma7\"].to_numpy()\n",
    "results[\"Baseline_lag1\"] = {\"WMAPE\": round(wmape(y_test, naive_pred), 4),\n",
    "                            \"MAE\":   round(float(mean_absolute_error(y_test, naive_pred)), 2)}\n",
    "results[\"Baseline_MA7\"]  = {\"WMAPE\": round(wmape(y_test, ma7_pred), 4),\n",
    "                            \"MAE\":   round(float(mean_absolute_error(y_test, ma7_pred)), 2)}\n",
    "\n",
    "results  # pick the smallest WMAPE/MAE; prefer the simpler model if scores are close\n",
    "\n",
    "# WMAPE — Weighted Mean Absolute Percentage Error - total error as a percent of total actuals - Overall we’re off by 15%\n",
    "# MAE — Mean Absolute Error - average dollar mistake Ex - On average, we’re off by $X per day/row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1540fae8-08c1-4a26-8659-a4ea4124936e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
